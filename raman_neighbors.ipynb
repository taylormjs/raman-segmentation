{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nuclei Segmentation using Local Raman pixel clusters (i.e. neighbors of each pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess imported\n",
      "module name : preprocess module package: \n",
      "Python version: 3.7.6 | packaged by conda-forge | (default, Jan  7 2020, 22:05:27) \n",
      "[Clang 9.0.1 ]\n",
      "TensorFlow version: 2.1.0\n",
      "\n",
      "Imports Complete.\n"
     ]
    }
   ],
   "source": [
    "# general python utility packages\n",
    "import os\n",
    "import platform\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import functools\n",
    "import itertools as it\n",
    "import copy\n",
    "\n",
    "# data science packages\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import anndata as ann\n",
    "import h5py\n",
    "\n",
    "\n",
    "# plotting packages\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# local imports\n",
    "import preprocess as pp\n",
    "import train \n",
    "import utils\n",
    "\n",
    "\n",
    "# recommended Python3 version >= 3.5\n",
    "print('Python version: {}'.format(platform.sys.version))\n",
    "\n",
    "\n",
    "# progress bar\n",
    "try:\n",
    "    from tqdm.notebook import tqdm\n",
    "except ImportError:\n",
    "    from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "# required TensorFlow version >= 2.0.0\n",
    "tf_version = tf.__version__\n",
    "print('TensorFlow version: {}'.format(tf_version))\n",
    "assert int(tf_version[0]) >= 2, \"Tensorflow version must be >= 2.0\"\n",
    "\n",
    "# seed random numbers for reproducibility\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "print('\\nImports Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-tuner in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (4.36.1)\n",
      "Requirement already satisfied: terminaltables in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (3.1.0)\n",
      "Requirement already satisfied: tabulate in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (0.8.7)\n",
      "Requirement already satisfied: colorama in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (0.4.3)\n",
      "Requirement already satisfied: numpy in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (1.17.2)\n",
      "Requirement already satisfied: future in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (0.18.0)\n",
      "Requirement already satisfied: requests in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from keras-tuner) (2.22.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from scikit-learn->keras-tuner) (0.14.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from requests->keras-tuner) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from requests->keras-tuner) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from requests->keras-tuner) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages (from requests->keras-tuner) (1.25.7)\n"
     ]
    }
   ],
   "source": [
    "#installations\n",
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in full dataset (un-balanced)\n",
    "pp_file = 'preprocessed_data.h5'\n",
    "raman_df_full = pd.read_hdf(pp_file, mode='r+', key='pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get background\n",
    "bg_mask = raman_df_full.background == True\n",
    "bg = raman_df_full[bg_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get foreground\n",
    "fg = raman_df_full[~bg_mask]\n",
    "\n",
    "# remove null values \n",
    "fg = fg[~fg.background.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide background spectra into train, test, val sets\n",
    "train_bg_mask = bg.image.isin(['D13_Pos19', 'D11.5_Pos13'])\n",
    "val_bg_mask = bg.image == 'D11_Pos4'\n",
    "test_bg_mask = bg.image == 'D8_Pos4'\n",
    "\n",
    "train_bg = bg[train_bg_mask]\n",
    "val_bg = bg[val_bg_mask]\n",
    "test_bg = bg[test_bg_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset random seed\n",
    "import time\n",
    "random.seed(int(time.time()))\n",
    "np.random.seed(int(time.time()))\n",
    "tf.random.set_seed(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide foreground spectra into train, test, val sets\n",
    "\n",
    "# choose a random sampling of images to go in each set\n",
    "fg_images = pd.Series(fg.image.unique())\n",
    "train_im, test_im, val_im = np.split(fg_images, [int(len(fg_images)*.6), int(len(fg_images)*.8)])\n",
    "\n",
    "# get dataframe with those images only\n",
    "train_fg = fg[fg.image.isin(train_im)]\n",
    "val_fg = fg[fg.image.isin(val_im)]\n",
    "test_fg = fg[fg.image.isin(test_im)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:8: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "  \n",
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:8: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_items] [items->None]\n",
      "\n",
      "  \n",
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3319: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['image', 'day', 'pos', 'cell_id', 'pixel_id', 'background']]\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:10: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:10: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_items] [items->None]\n",
      "\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing set saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->axis0] [items->None]\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block0_items] [items->None]\n",
      "\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# make unbalanced datasets and save to .h5 file\n",
    "x_train_pd = pd.concat([train_bg, train_fg])\n",
    "x_test_pd = pd.concat([test_bg, test_fg])\n",
    "x_val_pd = pd.concat([val_bg, val_fg])\n",
    "\n",
    "# save to .h5 file\n",
    "store_imb = pd.HDFStore('train_val_test_imb.h5')\n",
    "store_imb['train'] = x_train_pd\n",
    "print('training set saved')\n",
    "store_imb['test'] = x_test_pd\n",
    "print('testing set saved')\n",
    "store_imb['val'] = x_val_pd\n",
    "print('validation set saved')\n",
    "store_imb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train_test_val from h5 file\n",
    "file = 'train_val_test_ds.h5'\n",
    "x_train_pd = pd.read_hdf(file, mode='r+', key='x_train')\n",
    "labels_train = pd.read_hdf(file, mode='r+', key='y_train')\n",
    "x_val_pd = pd.read_hdf(file, mode='r+', key='x_val')\n",
    "labels_val = pd.read_hdf(file, mode='r+', key='y_val')\n",
    "x_test_pd = pd.read_hdf(file, mode='r+', key='x_test')\n",
    "labels_test = pd.read_hdf(file, mode='r+', key='y_test')\n",
    "\n",
    "# convert to numpy\n",
    "x_train_np = x_train_pd.to_numpy()\n",
    "x_val_np = x_val_pd.to_numpy()\n",
    "x_test_np = x_test_pd.to_numpy()\n",
    "\n",
    "# get full dataframes again\n",
    "x_train_full = pd.concat([labels_train, x_train_pd], axis=1)\n",
    "x_test_full = pd.concat([labels_val, x_val_pd], axis=1)\n",
    "x_val_full = pd.concat([labels_test, x_test_pd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training, validation sets and labels to tensors, labels one-hot encoded\n",
    "# training set\n",
    "x_train = tf.convert_to_tensor(x_train_np)\n",
    "le_train = LabelEncoder()\n",
    "y_le_train = le_train.fit_transform(~labels_train.background.to_numpy())\n",
    "y_train = tf.one_hot(y_le_train,depth=2) \n",
    "\n",
    "# validation set\n",
    "x_val = tf.convert_to_tensor(x_val_np)\n",
    "le_val = LabelEncoder()\n",
    "y_le_val = le_val.fit_transform(~labels_val.background.to_numpy())\n",
    "y_val = tf.one_hot(y_le_val,depth=2) #refers to foreground\n",
    "\n",
    "# test set\n",
    "x_test = tf.convert_to_tensor(x_test_np)\n",
    "le_test = LabelEncoder()\n",
    "y_le_test = le_test.fit_transform(~labels_test.background.to_numpy())\n",
    "y_test = tf.one_hot(y_le_test,depth=2) #refers to foreground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>day</th>\n",
       "      <th>pos</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>pixel_id</th>\n",
       "      <th>pix_x</th>\n",
       "      <th>pix_y</th>\n",
       "      <th>background</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>920</th>\n",
       "      <th>921</th>\n",
       "      <th>922</th>\n",
       "      <th>923</th>\n",
       "      <th>924</th>\n",
       "      <th>925</th>\n",
       "      <th>926</th>\n",
       "      <th>927</th>\n",
       "      <th>928</th>\n",
       "      <th>929</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>43620</td>\n",
       "      <td>D13_Pos19</td>\n",
       "      <td>D13</td>\n",
       "      <td>Pos19</td>\n",
       "      <td>D13_Pos19_cell15</td>\n",
       "      <td>D13_Pos19_cell15_pix25</td>\n",
       "      <td>84.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.396188</td>\n",
       "      <td>1.28518</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.790167</td>\n",
       "      <td>-1.568548</td>\n",
       "      <td>0.350659</td>\n",
       "      <td>-0.88775</td>\n",
       "      <td>-0.877704</td>\n",
       "      <td>-0.248378</td>\n",
       "      <td>0.961621</td>\n",
       "      <td>-3.907183</td>\n",
       "      <td>-3.82069</td>\n",
       "      <td>-2.700839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 938 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           image  day    pos           cell_id                pixel_id  pix_x  \\\n",
       "43620  D13_Pos19  D13  Pos19  D13_Pos19_cell15  D13_Pos19_cell15_pix25   84.0   \n",
       "\n",
       "       pix_y background         0        1  ...       920       921       922  \\\n",
       "43620   77.0      False  0.396188  1.28518  ... -2.790167 -1.568548  0.350659   \n",
       "\n",
       "           923       924       925       926       927      928       929  \n",
       "43620 -0.88775 -0.877704 -0.248378  0.961621 -3.907183 -3.82069 -2.700839  \n",
       "\n",
       "[1 rows x 938 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = 10, 20\n",
    "mask = x_train_full['image'] == 'D13_Pos19'\n",
    "day_images = x_train_full[mask]\n",
    "duo_mask = (day_images.pix_x == 84) & (day_images.pix_y == 77)\n",
    "# day_images[duo_mask].index[0\n",
    "day_images[duo_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recast all spectra into tensors of size k x k x 930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recast dataframe spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in imbalanced dataset\n",
    "# x_train_pd = pd.read_hdf('train_val_test_imb.h5', mode='a', key='train')\n",
    "# x_test_pd = pd.read_hdf('train_val_test_imb.h5', mode = 'a', key='test')\n",
    "# x_val_pd = pd.read_hdf('train_val_test_imb.h5', mode = 'a', key='val')\n",
    "\n",
    "# load down-sampled dataset\n",
    "x_train_pd = pd.read_hdf('train_val_test_ds.h5', mode='a', key='x_train')\n",
    "x_test_pd = pd.read_hdf('train_val_test_ds.h5', mode = 'a', key='x_test')\n",
    "x_val_pd = pd.read_hdf('train_val_test_ds.h5', mode = 'a', key='x_val')\n",
    "\n",
    "y_train_pd = pd.read_hdf('train_val_test_ds.h5', mode='a', key='y_train')\n",
    "y_test_pd = pd.read_hdf('train_val_test_ds.h5', mode = 'a', key='y_test')\n",
    "y_val_pd = pd.read_hdf('train_val_test_ds.h5', mode = 'a', key='y_val')\n",
    "\n",
    "x_train_pd = pd.concat([y_train_pd, x_train_pd], axis=1)\n",
    "x_test_pd = pd.concat([y_test_pd, x_test_pd], axis=1)\n",
    "x_val_pd = pd.concat([y_val_pd, x_val_pd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in both train and test: set()\n",
      "Images in both train and val: {'D11.5_Pos13'}\n",
      "Images in both val and test: {'D8_Pos4'}\n"
     ]
    }
   ],
   "source": [
    "# make sure there aren't any overlapping images in train, val, or test sets\n",
    "print(f'Images in both train and test: {set(x_train_pd.image).intersection(set(x_test_pd.image))}')\n",
    "print(f'Images in both train and val: {set(x_train_pd.image).intersection(set(x_val_pd.image))}')\n",
    "print(f'Images in both val and test: {set(x_val_pd.image).intersection(set(x_test_pd.image))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions for getting nearest neighbors\n",
    "\n",
    "# get nearest neighbors from a pandas dataframe, given pixel info\n",
    "\n",
    "def image_mask(df, image):\n",
    "    return df[df.image == image]\n",
    "\n",
    "\n",
    "def get_neighbor_ix(x, y, k):\n",
    "    ''' \n",
    "        Just returns a list of the pixels immediately around x and y, \n",
    "        enough to form a k x k grid\n",
    "    '''\n",
    "    ixs = list(range(-k//2+1, k//2+1))\n",
    "    neighbor_pixels = [(x+i, y+j) for i in ixs for j in ixs]\n",
    "    return neighbor_pixels\n",
    "\n",
    "\n",
    "def get_neighbors_from_pixels(df, x, y, k=3):\n",
    "    ''' \n",
    "        Given an x and y coordinate, find the k nearest neighbors of x and y. \n",
    "        Assumes that x and y coordinates come from same image\n",
    "    '''\n",
    "    # get list of local rows to consider: eg. k = 3 -> [-1,0,1]; k = 5 -> [-2, -1, 0, 1, 2]\n",
    "    # get list of neighbors that would be 1 away\n",
    "    neighbor_pixels = get_neighbor_ix(x, y, k)\n",
    "    neighbors = []\n",
    "    for n in neighbor_pixels:\n",
    "        x_pix, y_pix = n[0], n[1]\n",
    "        mask = (df.pix_x == x_pix) & (df.pix_y == y_pix)\n",
    "        row = df[mask]\n",
    "        if row.shape[0] > 0:\n",
    "            neighbors.append(row)\n",
    "    return pd.concat(neighbors, axis=0)\n",
    "\n",
    "\n",
    "def impute_from_df_mean(mini_df, x, y, k=3, ix=8):\n",
    "    ''' \n",
    "    Given the neighbors of x and y, assembles a \n",
    "    k x k tensor represnting the pixels around the point \n",
    "    x and y\n",
    "    '''\n",
    "    n = mini_df.shape[0]\n",
    "    if n == k**2: return mini_df\n",
    "    \n",
    "    # if still missing values, imput with the mean of available values\n",
    "    mean = mini_df.iloc[:,ix:].mean()\n",
    "    prepend = mini_df.iloc[0,:4]\n",
    "    bg_label = pd.Series({'background': mini_df.iloc[0,7]})\n",
    "    cell_id = pd.Series({'cell_id': 'None'})\n",
    "    \n",
    "    neighbor_pixels = get_neighbor_ix(x, y, k)\n",
    "    NEW_ROWS = []\n",
    "    pixels_present = set(list(zip(mini_df.pix_x, mini_df.pix_y)))\n",
    "    for pix_x, pix_y in neighbor_pixels:\n",
    "        if (pix_x, pix_y) not in pixels_present:\n",
    "            pixels = pd.Series({'pix_x':pix_x, 'pix_y':pix_y})\n",
    "            new_row = pd.concat([prepend, pixels, bg_label, mean])\n",
    "            NEW_ROWS.append(new_row)\n",
    "    ADD_ROWS = pd.concat(NEW_ROWS, axis=1)\n",
    "    return pd.concat([mini_df, ADD_ROWS.T], axis=0)\n",
    "\n",
    "\n",
    "def assemble_tensor_from_df(mini_df, x_center, y_center, k=3):\n",
    "    '''\n",
    "        Given the x center and the y center, assemble two tensors\n",
    "        around x_center and y_center - the tensor of spectra\n",
    "        and a resulting label (either fg or bg)\n",
    "    '''\n",
    "    # sort df, then reshape\n",
    "    sorted_df = mini_df.sort_values(['pix_x', 'pix_y'])\n",
    "    sorted_np = sorted_df.iloc[:,8:].to_numpy()\n",
    "    return np.reshape(sorted_np, newshape=(k,k,sorted_np.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors_from_df(dataframe, k=3):\n",
    "    ''' \n",
    "        Run through all the functions to get input tensors for \n",
    "        the neural network\n",
    "    '''\n",
    "    if k == 1:\n",
    "        return dataframe.iloc[:,8:].to_numpy().astype('float64'), ~dataframe.background\n",
    "    tensor_list = []\n",
    "    labels = []\n",
    "    # get image list\n",
    "    image_list = dataframe.image.unique()\n",
    "    for image in tqdm(image_list):\n",
    "        print(f'image name: {image}')\n",
    "        # get mask of that image\n",
    "        df = image_mask(dataframe, image)\n",
    "        for index, row in df.iterrows():\n",
    "            cell_label = int(not row.background) # 1 for cell, 0 for bg\n",
    "            x, y = row.pix_x, row.pix_y\n",
    "            # get the mini_df\n",
    "            neighbors = get_neighbors_from_pixels(df, x, y, k=3)\n",
    "            # impute any missing values\n",
    "            imp_neighbors = impute_from_df_mean(neighbors, x, y, k=k)\n",
    "            # now assemble tensor\n",
    "            tensor = assemble_tensor_from_df(imp_neighbors, x, y, k=k)\n",
    "            tensor_list.append(tensor)\n",
    "            labels.append(cell_label)\n",
    "    test_tensors_np = np.array(tensor_list)\n",
    "    return test_tensors_np.astype('float64'), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find neighbors for all pixels\n",
    "df = raman_df_full[raman_df_full.image == ims[4]]\n",
    "n_list = []\n",
    "for index, row in (df.iterrows()):\n",
    "    x, y = row.pix_x, row.pix_y\n",
    "    neighbors = get_neighbors_from_pixels(df, x, y, k=3)\n",
    "    n_list.append(neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at histogram of num neighbors\n",
    "n_sizes = np.array([n.shape[0] for n in n_list])\n",
    "plt.hist(n_sizes)\n",
    "plt.title(f'distribution of n_neighbors\\n Day {ims[4]}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save all as .h5 files for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44fc74d03a542bba1c9143b3650b985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=43), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: D12_Pos14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: D8.5_Pos1\n",
      "image name: D14_Pos1\n",
      "image name: D11.5_Pos6\n",
      "image name: D12_Pos18\n",
      "image name: D12.5_Pos17\n",
      "image name: D9_Pos19\n",
      "image name: D14_Pos16\n",
      "image name: D9.5_Pos17\n",
      "image name: D11.5_Pos7\n",
      "image name: D10_Pos12\n",
      "image name: D12_Pos13\n",
      "image name: D10.5_Pos18\n",
      "image name: D13_Pos16\n",
      "image name: D9_Pos4\n",
      "image name: D9_Pos8\n",
      "image name: D10_Pos19\n",
      "image name: D9.5_Pos3\n",
      "image name: D13_Pos11\n",
      "image name: D12_Pos7\n",
      "image name: D8.5_Pos6\n",
      "image name: D9.5_Pos8\n",
      "image name: D12.5_Pos10\n",
      "image name: D11_Pos2\n",
      "image name: D8_Pos5\n",
      "image name: D11.5_Pos19\n",
      "image name: D11_Pos5\n",
      "image name: D9.5_Pos10\n",
      "image name: D10.5_Pos8\n",
      "image name: D12_Pos1\n",
      "image name: D10_Pos4\n",
      "image name: D13_Pos6\n",
      "image name: D9_Pos12\n",
      "image name: D11.5_Pos12\n",
      "image name: D12.5_Pos1\n",
      "image name: D10.5_Pos19\n",
      "image name: D10.5_Pos14\n",
      "image name: D10_Pos8\n",
      "image name: D11_Pos17\n",
      "image name: D11.5_Pos15\n",
      "image name: D12_Pos0\n",
      "image name: D11.5_Pos14\n",
      "image name: D8_Pos4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# convert train, test, and validation sets into tensors\n",
    "# get test tensors\n",
    "test_tensors, test_labels = get_tensors_from_df(x_test_pd, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test tensors\n",
    "hf_test = h5py.File('ds_tf_tensors_test.h5', 'w')\n",
    "hf_test.create_dataset('x_test', data=test_tensors)\n",
    "hf_test.create_dataset('y_test', data=test_labels)\n",
    "hf_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a7c230df8844be83c90db0cd28144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: D14_Pos11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: D9_Pos18\n",
      "image name: D13_Pos1\n",
      "image name: D12_Pos6\n",
      "image name: D11_Pos8\n",
      "image name: D9.5_Pos9\n",
      "image name: D8.5_Pos11\n",
      "image name: D13_Pos17\n",
      "image name: D11_Pos9\n",
      "image name: D14_Pos7\n",
      "image name: D9_Pos15\n",
      "image name: D12.5_Pos11\n",
      "image name: D9.5_Pos11\n",
      "image name: D8_Pos9\n",
      "image name: D11_Pos4\n",
      "image name: D8_Pos8\n",
      "image name: D11.5_Pos1\n",
      "image name: D12_Pos12\n",
      "image name: D14_Pos10\n",
      "image name: D14_Pos6\n",
      "image name: D8_Pos4\n",
      "image name: D9.5_Pos5\n",
      "image name: D13_Pos0\n",
      "image name: D12.5_Pos7\n",
      "image name: D11_Pos11\n",
      "image name: D10.5_Pos4\n",
      "image name: D10.5_Pos13\n",
      "image name: D8.5_Pos10\n",
      "image name: D11.5_Pos0\n",
      "image name: D8.5_Pos0\n",
      "image name: D9_Pos2\n",
      "image name: D9_Pos14\n",
      "image name: D11_Pos10\n",
      "image name: D12.5_Pos6\n",
      "image name: D11.5_Pos13\n",
      "image name: D10_Pos2\n",
      "image name: D10_Pos14\n",
      "image name: D10.5_Pos12\n",
      "image name: D10_Pos18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get validation tensors\n",
    "val_tensors, val_labels = get_tensors_from_df(x_val_pd, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation tensors\n",
    "hf_val = h5py.File('ds_tf_tensors_val.h5', 'w')\n",
    "hf_val.create_dataset('x_val', data=val_tensors)\n",
    "hf_val.create_dataset('y_val', data=val_labels)\n",
    "hf_val.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b0f1a2e97343adb09c328380cda359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=117), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: D10.5_Pos15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tjamesso/miniconda3/envs/broad/lib/python3.7/site-packages/ipykernel_launcher.py:61: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image name: D8.5_Pos12\n",
      "image name: D10_Pos1\n",
      "image name: D9_Pos5\n",
      "image name: D12.5_Pos14\n",
      "image name: D10_Pos13\n",
      "image name: D9_Pos11\n",
      "image name: D8_Pos7\n",
      "image name: D8.5_Pos5\n",
      "image name: D13_Pos7\n",
      "image name: D11.5_Pos5\n",
      "image name: D8.5_Pos4\n",
      "image name: D13_Pos15\n",
      "image name: D11_Pos19\n",
      "image name: D9.5_Pos15\n",
      "image name: D13_Pos9\n",
      "image name: D8_Pos6\n",
      "image name: D9_Pos17\n",
      "image name: D13_Pos3\n",
      "image name: D9_Pos16\n",
      "image name: D13_Pos5\n",
      "image name: D9.5_Pos18\n",
      "image name: D9.5_Pos16\n",
      "image name: D8.5_Pos13\n",
      "image name: D14_Pos8\n",
      "image name: D9_Pos10\n",
      "image name: D13_Pos18\n",
      "image name: D9.5_Pos19\n",
      "image name: D8.5_Pos2\n",
      "image name: D13_Pos10\n",
      "image name: D10.5_Pos7\n",
      "image name: D14_Pos19\n",
      "image name: D13_Pos4\n",
      "image name: D8.5_Pos7\n",
      "image name: D12.5_Pos8\n",
      "image name: D11.5_Pos17\n",
      "image name: D14_Pos12\n",
      "image name: D11_Pos16\n",
      "image name: D11.5_Pos3\n",
      "image name: D11_Pos3\n",
      "image name: D12_Pos10\n",
      "image name: D13_Pos12\n",
      "image name: D10_Pos11\n",
      "image name: D14_Pos9\n",
      "image name: D11.5_Pos10\n",
      "image name: D9.5_Pos14\n",
      "image name: D9_Pos0\n",
      "image name: D13_Pos8\n",
      "image name: D12_Pos3\n",
      "image name: D12.5_Pos9\n",
      "image name: D14_Pos13\n",
      "image name: D10.5_Pos1\n",
      "image name: D9_Pos6\n",
      "image name: D9.5_Pos1\n",
      "image name: D8.5_Pos14\n",
      "image name: D11_Pos7\n",
      "image name: D11_Pos18\n",
      "image name: D10.5_Pos10\n",
      "image name: D10.5_Pos0\n",
      "image name: D14_Pos14\n",
      "image name: D12.5_Pos16\n",
      "image name: D14_Pos18\n",
      "image name: D14_Pos0\n",
      "image name: D14_Pos17\n",
      "image name: D13_Pos13\n",
      "image name: D12_Pos11\n",
      "image name: D10.5_Pos16\n",
      "image name: D11_Pos13\n",
      "image name: D9_Pos13\n",
      "image name: D11_Pos6\n",
      "image name: D12_Pos17\n",
      "image name: D14_Pos5\n",
      "image name: D12.5_Pos3\n",
      "image name: D12.5_Pos0\n",
      "image name: D13_Pos19\n",
      "image name: D14_Pos2\n",
      "image name: D12_Pos8\n",
      "image name: D12_Pos4\n",
      "image name: D10_Pos6\n",
      "image name: D11.5_Pos18\n",
      "image name: D12_Pos15\n",
      "image name: D9.5_Pos0\n",
      "image name: D9_Pos7\n",
      "image name: D12.5_Pos13\n",
      "image name: D10.5_Pos17\n",
      "image name: D12_Pos5\n",
      "image name: D10_Pos5\n",
      "image name: D12.5_Pos18\n",
      "image name: D10.5_Pos11\n",
      "image name: D11.5_Pos8\n",
      "image name: D14_Pos3\n",
      "image name: D14_Pos4\n",
      "image name: D12.5_Pos5\n",
      "image name: D11_Pos0\n",
      "image name: D8.5_Pos8\n",
      "image name: D9.5_Pos2\n",
      "image name: D9.5_Pos12\n",
      "image name: D12.5_Pos12\n",
      "image name: D11_Pos1\n",
      "image name: D10_Pos16\n",
      "image name: D12_Pos16\n",
      "image name: D12.5_Pos2\n",
      "image name: D8.5_Pos3\n",
      "image name: D10_Pos17\n",
      "image name: D14_Pos15\n",
      "image name: D13_Pos2\n",
      "image name: D12_Pos9\n",
      "image name: D11_Pos15\n",
      "image name: D11.5_Pos16\n",
      "image name: D13_Pos14\n",
      "image name: D12_Pos19\n",
      "image name: D10.5_Pos6\n",
      "image name: D12_Pos2\n",
      "image name: D8.5_Pos9\n",
      "image name: D12.5_Pos15\n",
      "image name: D9_Pos9\n",
      "image name: D11.5_Pos13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get train tensors\n",
    "train_tensors, train_labels = get_tensors_from_df(x_train_pd, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(808, 930)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training tensors\n",
    "hf_train = h5py.File('ds_tf_tensors_train.h5', 'w')\n",
    "hf_train.create_dataset('x_train', data=train_tensors)\n",
    "hf_train.create_dataset('y_train', data=train_labels)\n",
    "hf_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nearest neighbors from a 3D tensor (first reshape, then get nearest neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all arrays to tensors\n",
    "x_train_tf = tf.convert_to_tensor(train_tensors, dtype='float32')\n",
    "x_test_tf = tf.convert_to_tensor(test_tensors, dtype='float32')\n",
    "x_val_tf = tf.convert_to_tensor(val_tensors, dtype='float32')\n",
    "\n",
    "y_train_tf = tf.convert_to_tensor(train_labels)\n",
    "y_test_tf = tf.convert_to_tensor(test_labels)\n",
    "y_val_tf = tf.convert_to_tensor(val_labels)\n",
    "\n",
    "# change to one-hot encodings\n",
    "y_train_one_hot = tf.one_hot(y_train_tf,depth=2)\n",
    "y_test_one_hot = tf.one_hot(y_test_tf,depth=2)\n",
    "y_val_one_hot = tf.one_hot(y_val_tf,depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(808,) (544,) (278,)\n",
      "(808, 5, 5, 930) (544, 5, 5, 930) (278, 5, 5, 930)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_tf.shape, y_test_tf.shape, y_val_tf.shape)\n",
    "print(x_train_tf.shape, x_test_tf.shape, x_val_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from kerastuner import HyperModel\n",
    "\n",
    "# Model definition    \n",
    "class raman_cnn(HyperModel):\n",
    "    \n",
    "    def __init__(self, kernel_size=2):\n",
    "        self.kernel_size=kernel_size\n",
    "        \n",
    "    def build(self, hp):\n",
    "        model = tf.keras.Sequential()\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=hp.Choice(\n",
    "                    'num_filters',\n",
    "                    values=[32, 64],\n",
    "                    default=64), \n",
    "                    kernel_size=self.kernel_size, strides=(1,1),\n",
    "                                activation='relu'))\n",
    "        model.add(tf.keras.layers.MaxPool2D())\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu')))\n",
    "        model.add(tf.keras.layers.Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            )))\n",
    "        model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "        model.add(tf.keras.layers.Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            )))\n",
    "        model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "        # Use binary crossentropy loss\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3)),\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy', 'AUC'])\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-3ce417ef6688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate the weights for each class so that we can balance the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m weights = class_weight.compute_class_weight('balanced',\n\u001b[0;32m----> 3\u001b[0;31m                                             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                             labels.numpy())\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the weights for each class so that we can balance the data\n",
    "weights = class_weight.compute_class_weight('balanced',\n",
    "                                            np.unique(labels),\n",
    "                                            labels.numpy())\n",
    "\n",
    "# Add the class weights to the training                                         \n",
    "history = model.fit(x, y, epochs=20, batch_size=32, class_weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch, Hyperband\n",
    "\n",
    "# define parameters\n",
    "HYPERBAND_MAX_EPOCHS = 40\n",
    "MAX_TRIALS = 20\n",
    "EXECUTION_PER_TRIAL = 2\n",
    "\n",
    "# define model\n",
    "model = raman_cnn(kernel_size=2)\n",
    "\n",
    "tuner = Hyperband(\n",
    "    model,\n",
    "    objective='val_accuracy',\n",
    "    seed=0,\n",
    "    executions_per_trial=EXECUTION_PER_TRIAL,\n",
    "    directory='hyperband',\n",
    "    project_name='raman',\n",
    "    max_epochs=HYPERBAND_MAX_EPOCHS\n",
    ")\n",
    "\n",
    "# conduct hyperparameter search\n",
    "N_EPOCH_SEARCH = 20\n",
    "tuner.search(x_train_tf, y_train_one_hot, epochs=N_EPOCH_SEARCH, validation_data=(x_val_tf, y_val_one_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544/544 [==============================] - ETA: 4s - loss: 0.0791 - accuracy: 0.9688 - AUC: 0.99 - 0s 593us/sample - loss: 0.1871 - accuracy: 0.9724 - AUC: 0.9945\n"
     ]
    }
   ],
   "source": [
    "# evaluate on best model\n",
    "\n",
    "# tuner.results_summary()\n",
    "\n",
    "# Retrieve the best model.\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model.\n",
    "loss, accuracy, auc = best_model.evaluate(x_test_tf, y_test_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_test_tf)\n",
    "# get classification report and roc curve\n",
    "y_test_int = y_test_one_hot[:,1].numpy()\n",
    "y_pred_int = y_pred[:,1]\n",
    "\n",
    "\n",
    "# plotting roc curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_int, y_pred_int)\n",
    "plt.title('ROC Curve after CNN + cluster classifier')\n",
    "plt.plot(fpr, tpr, color='orange', linestyle='--', label='ROC curve');\n",
    "plt.plot([0, 1], [0, 1], color='blue', label='random classifier');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on images from .dat files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recast images to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_pd.image.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load complete test tensors and image names\n",
    "load_test_images = False\n",
    "if load_test_images:\n",
    "    test_image_names = utils.read_pickle('test_image_names.pkl')\n",
    "    print('image names loaded')\n",
    "    raman_specs = utils.read_pickle('test_images.pkl')\n",
    "    print('full test images loaded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1: D8.5_Pos1\n",
      "finger-print region extracted\n",
      "sharp peaks removed\n",
      "fluorescence removed\n",
      "horizontal mean subtracted\n",
      "cell complete\n"
     ]
    }
   ],
   "source": [
    "# get a random image image and run through the pre-processing pipeline\n",
    "image_ix = np.random.randint(0, high=len(raman_specs))\n",
    "print(f'image {image_ix}: {raman_specs[image_ix][0]}')\n",
    "image_vec = raman_specs[image_ix][1]\n",
    "\n",
    "image_fp = pp.get_fingerprint_region(image_vec, start_ix=410)\n",
    "print('finger-print region extracted')\n",
    "image_or = pp.remove_sharp_peaks_2d_iter(image_fp, win_size=10, threshold=5)\n",
    "print('sharp peaks removed')\n",
    "image_fr = pp.remove_fluorescence(image_or, method='als')\n",
    "print('fluorescence removed')\n",
    "image_hz = image_fr - np.mean(image_fr, axis=1, keepdims=True)\n",
    "print('horizontal mean subtracted')\n",
    "image_ss = StandardScaler().fit_transform(image_hz)\n",
    "print('cell complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, d = image_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample an image, get tensors from it\n",
    "k = 3\n",
    "img = np.reshape(image_ss, (100,100,d))\n",
    "# add 0 padding\n",
    "# img_padded = np.pad(img, (2,2))[:,:,2:1342]\n",
    "tensor_list = []\n",
    "m,n, depth = img.shape\n",
    "for r in range(m-(k-1)):\n",
    "    for c in range(n-(k-1)):\n",
    "        tensor_list.append(img[r:r+k, c:c+k, :])\n",
    "tensor_np = np.array(tensor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9604, 3, 3, 930), (100, 100, 930), TensorShape([808, 5, 5, 930]))"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_np.shape, img.shape, x_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image_180(image):\n",
    "    ''' rotate an image by 180 degrees '''\n",
    "    return np.rot90(image,2,(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 128 but received input with shape [None, 32]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-467-fbfee7386468>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg_rot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotate_image_180\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2360\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2362\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[0;34m(input_iterator)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_feed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     outputs = strategy.experimental_run_v2(\n\u001b[0;32m---> 85\u001b[0;31m         per_replica_function, args=args)\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;31m# Out of PerReplica outputs reduce or pick values to return.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     all_outputs = dist_utils.unwrap_output_dict(\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mexperimental_run_v2\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m    761\u001b[0m       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),\n\u001b[1;32m    762\u001b[0m                                 convert_by_default=False)\n\u001b[0;32m--> 763\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   1817\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2164\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_predict_on_batch\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0;31m# Note that the x and batch_index is already per-replica value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(model, x, standalone)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager_learning_phase_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_on_batch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    776\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m                   \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOperatorNotAllowedInGraphError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m       \u001b[0;31m# `outputs` will be the inputs to the next layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;31m# are casted, not before.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[0;32m--> 737\u001b[0;31m                                               self.name)\n\u001b[0m\u001b[1;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[1;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[0;32m~/miniconda3/envs/broad/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;34m' incompatible with the layer: expected axis '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;34m' of input shape to have value '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                 ' but received input with shape ' + str(shape))\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;31m# Check shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer dense is incompatible with the layer: expected axis -1 of input shape to have value 128 but received input with shape [None, 32]"
     ]
    }
   ],
   "source": [
    "img_pred = best_model.predict(tensor_np)[:,1]\n",
    "img_reshaped = np.reshape(img_pred, (m-2, n-2))\n",
    "img_rot = rotate_image_180(img_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ground truth and nucleaize's best segmentation\n",
    "nuclei_stain_image = plt.imread(f'./data/nuclei_stain/{raman_specs[image_ix][0]}.tif')\n",
    "segmentation_image = plt.imread(f'./data/labelled/{raman_specs[image_ix][0]}.tiff')\n",
    "\n",
    "# get window of interest from these images\n",
    "temp_loc = (368,355)\n",
    "temp_dims = 1312\n",
    "nuclei_stain_image_cropped = nuclei_stain_image[temp_loc[0]:temp_loc[0]+temp_dims,temp_loc[1]:temp_loc[1]+temp_dims]\n",
    "segmentation_image_cropped = segmentation_image[temp_loc[0]:temp_loc[0]+temp_dims,temp_loc[1]:temp_loc[1]+temp_dims]\n",
    "\n",
    "# get title\n",
    "image_name = raman_specs[image_ix][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot image side by side with original image\n",
    "norm = cm.Normalize(vmin=0, vmax=1)\n",
    "fig, axs = plt.subplots(1, 3,figsize=(15,15))\n",
    "im1 = axs[0].imshow(img_rot)\n",
    "axs[0].set_title(f'Predicted image using Patch CNN\\n{image_name}')\n",
    "im2 = axs[1].imshow(nuclei_stain_image_cropped)\n",
    "axs[1].set_title(f'Original image\\n{image_name}')\n",
    "im3 = axs[2].imshow(segmentation_image_cropped);\n",
    "axs[2].set_title(f'State of the art Segmentation\\n{image_name}')\n",
    "\n",
    "# add colorbar\n",
    "fig.colorbar(im1, ax=axs[0], shrink=.25)\n",
    "fig.colorbar(im2, ax=axs[1], shrink=.25)\n",
    "fig.colorbar(im3, ax=axs[2], shrink=.25);\n",
    "\n",
    "# save figure\n",
    "plt.savefig(f'results/patch_CNN_k=5/nn_image_{image_ix}');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'D9.5_Pos8' in x_test_pd.image.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** - decision made to not apply padding for the sake of time. Consider adding back in later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNFINISHED CODE (ADD LATER IF TIME PERMITS)\n",
    "# for raman vectors, if 0 present (at a corner), fill in with means\n",
    "def impute_small_tensor(tensor):\n",
    "    # check if 0 in tensor\n",
    "    if 0 not in tensor: return tensor\n",
    "    pass\n",
    "\n",
    "def impute_from_image_mean(tensor_np):\n",
    "    pass\n",
    "\n",
    "def get_test_image_tensors(raman_vec, k=3):\n",
    "    ''' \n",
    "        Given an input vector, reshapes and finds all k x k\n",
    "        clusters. Assumes tensors has already been pre-processed\n",
    "    '''\n",
    "    m, n_features = raman_vec.shape\n",
    "    raman_tensor = np.reshape(raman_vec, (100,100, n_features))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
